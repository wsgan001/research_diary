#### [Membership Inference Attacks Against Machine Learning Models](https://www.cs.cornell.edu/~shmat/shmat_oak17.pdf)

This is the most interesting paper I have read this week. It shows a surprising method about membership inference attacks with the help of machine learning models.

If the target model is accessed by the attacker, the similar models with the same type and architecture as the target model can be trained. 

> the main idea behind our shadow training technique is that similar models trained on relatively similar data records using the same service behave in a similar way

In this paper, a binary classification model is trained to predicate the membership. The most challenging is the training data, How we can obtain these data? In fact, we can **produce** some very similar data, by the target model which is accessible, and we can also labeled these data. Finally we can train out attack model by this labeled data.

This paper also reveals an interesting conclusion: instead of the usual tradeoff between utility and privacy, machine learning research and privacy research have similar objectives in this case.

I still have some questions about this paper, why we should trained k shadow models, not a single one? The authors explained that larger k can improve the accuracy of attack model? But why and how larger k can make this improvement?