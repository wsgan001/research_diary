#### [Hearing Your Voice is Not Enough: An Articulatory Gesture Based Liveness Detection for Voice Authentication](https://acmccs.github.io/papers/p57-zhangA.pdf)

#### Intro

- previous works either need cumbersome operations (Chen et al., Zhang et al.) or have low accuracy
- our work: measure the characteristic of users' habitual ways of speaking on the phones, i.e., have the phone held either to users' ear or in front of the mouth

#### Attack Model

- our liveness detection system could be extended to a text-independent system
- doppler shift: $\Delta fâˆ\frac{v\cos{\alpha}}{c}f_0$
- loudspeaker relies on solely the diaphragm that moves in one dimension

#### System model

- the key idea is to leverage the mobile audio hardware advances to sense the articulatory gesture
- our system works when the users hold the phones with their nature habits, while the prior requires users to behavior in some predefined manners
- Doppler shifts Extraction -> Feature Extraction -> Wavelet-based Denoising -> Similarity Comparison -> Detection

