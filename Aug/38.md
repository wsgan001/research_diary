#### [EyeTell: Video-Assisted Touchscreen Keystroke Inference from Eye Movements](https://www.eecis.udel.edu/~ruizhang/paper/sun-NDSS16.pdf)

- many keystroke inference attacks rely on analyzing a video recording the victim's typing process
- EyeTell is a video-assisted keystroke inference from eye movements

#### Related work

- video-based attacks: Backes et al. recovered the content on a computer screen from **its reflection on nearby objects**
- Sun et al. showed the keystroke can be actually inferred from the motion of a tablet's backside
- sensor-based attacks: accelerometer data of a mobile device can be used to infer the victim's password
- wifi-based attacks: different keystrokes lead to distinct changes in wireless channel and the corresponding CSI

- a victim's gaze trace can reveal his typing sequence on a soft keyboard
  - feature-based methods: contours, eye corner
  - appearance-based methods: directly the eye image

#### Overview

- video recoding
- gaze trace extraction: eye detection -> limbus detection -> gaze trace estimation-
- trace decoding: 
  - identify the turning points
  - convert each segment into a small set of candidate vectors
  - enumerate all possible combinations of candidate vectors, check whether or not the combination can be mapped into a valid input sequence
  - rank the valid input sequences, choose the final set